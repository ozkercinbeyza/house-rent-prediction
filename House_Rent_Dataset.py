# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MaN5y-HQeLdzOLU5Oq1jOLe7fZJUDtcR
"""

# Google Drive'ı kullanabilmek için 'drive' modülünü Google Colab'dan içe aktarıyoruz
from google.colab import drive

# Drive'ı bağlamak için bu komutu çalıştırıyoruz
drive.mount('/content/drive')

# Gerekli kütüphaneleri içe aktarıyoruz
import pandas as pd  # veri analizi için en popüler kütüphane

# CSV dosyasını pandas ile okuyoruz
file_path = '/content/drive/MyDrive/House_Rent_Dataset.csv'  # dosya yolu
df = pd.read_csv(file_path)  # CSV dosyasını DataFrame olarak okuruz
print("Dosya başarıyla yüklendi ve veri çerçevesine aktarıldı")

# Veri çerçevesinin ilk 5 satırını görüntülemek için:
df.head()

# Veri seti hakkında genel bilgi almak için:
df.info()  # Hangi sütunlar var, veri tipleri neler, eksik veri var mı gibi bilgiler verir

# Sütun adlarını listelemek için
df.columns  # Tüm sütun isimlerini verir

#Sayısal değişkenler için istatistiksel özet
df.describe()

# Veri kümesinin boyutu (satır,sütun sayısı)
df.shape

#Her sütunun veri tipini gösterme
df.dtypes

#Her sütundaki benzersiz değerleri gösterme
df.nunique()

#Her sütunda toplam eksik değer sayısı
df.isnull().sum()

df.sample(5)

# Gerekli kütüphaneler
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Şehir ve mobilya dağılımı hesaplanıyor
city_counts = df['City'].value_counts()
furnishing_counts = df['Furnishing Status'].value_counts()

# 🎨 Soft mavi tonlar paleti
soft_blues = ["#ADD8E6", "#B0E0E6", "#AFEEEE", "#87CEEB", "#D0E7F5"]

# 📊 Şehirlerin dağılımı
plt.figure(figsize=(10, 6))
sns.barplot(
    x=city_counts.index,
    y=city_counts.values,
    palette=soft_blues
)
plt.title("Şehir Bazında Ev Sayıları", fontsize=16)
plt.xlabel("Şehir", fontsize=12)
plt.ylabel("Ev Sayısı", fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# 📊 Mobilya durumları
plt.figure(figsize=(8, 5))
sns.barplot(
    x=furnishing_counts.index,
    y=furnishing_counts.values,
    palette=soft_blues[:len(furnishing_counts)]  # Renk sayısını duruma göre kısalt
)
plt.title("Mobilya Durumuna Göre Ev Sayısı", fontsize=16)
plt.xlabel("Mobilya Durumu", fontsize=12)
plt.ylabel("Ev Sayısı", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 90 m² ve üzeri evleri filtrele
df_filtered = df[df["Size"] >= 90]

# Ortalama kira değerlerini hesapla
size_rent = df_filtered.groupby("Size")["Rent"].mean().reset_index()

# Gerekirse ilk 30 değeri al
size_rent = size_rent.sort_values(by="Size").head(30)

# Grafik
plt.figure(figsize=(14, 6))
sns.barplot(data=size_rent, x="Size", y="Rent", color="#87CEEB")  # soft mavi (sky blue)

plt.title("📏 90 m² ve Üzeri Evler İçin Ortalama Kira", fontsize=14)
plt.xlabel("Ev Büyüklüğü (m²)")
plt.ylabel("Ortalama Kira (₹)")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Şehirlere göre ortalama kira hesapla
city_rent = df.groupby("City")["Rent"].mean().reset_index().sort_values(by="Rent", ascending=False)

# Grafik çizimi
plt.figure(figsize=(10, 6))
sns.barplot(data=city_rent, x="City", y="Rent", color="#ADD8E6")  # LightBlue tonu

# Başlık ve eksen etiketleri
plt.title("🏙️ Şehirlere Göre Ortalama Kira", fontsize=14)
plt.xlabel("Şehir")
plt.ylabel("Ortalama Kira (₹)")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.4)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 🔹 BHK (oda sayısı) göre ortalama kira hesapla
bhk_rent = df.groupby("BHK")["Rent"].mean().reset_index()

# 🔹 Grafik
plt.figure(figsize=(8, 5))
sns.barplot(data=bhk_rent, x="BHK", y="Rent", palette="Blues")
plt.title("🛏️ Oda Sayısına Göre Ortalama Kira (Rent)", fontsize=13)
plt.xlabel("Oda Sayısı (BHK)", fontsize=12)
plt.ylabel("Ortalama Kira (₹)", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 🔹 Örnek: Banyo ve kira bilgileri olan bir DataFrame'in olduğunu varsayıyoruz.
# df içinde "Bathroom" ve "Rent" sütunlarının bulunduğundan emin olalım.

# 🔍 Banyo sayısına göre ortalama kira hesaplanıyor
bathroom_rent = df.groupby("Bathroom")["Rent"].mean().reset_index()

# 🎨 Grafik çizimi
plt.figure(figsize=(8, 5))  # Grafik boyutu
sns.barplot(
    data=bathroom_rent,        # Veri kaynağı
    x="Bathroom",              # X ekseni: Banyo sayısı
    y="Rent",                  # Y ekseni: Ortalama kira
    palette="Blues"            # Soft mavi tonlar
)

# 🖼️ Başlık ve eksen adları
plt.title("🛁 Banyo Sayısına Göre Ortalama Kira", fontsize=14)
plt.xlabel("Banyo Sayısı", fontsize=12)
plt.ylabel("Ortalama Kira (₹)", fontsize=12)

# 🧼 Arayüz düzenlemeleri
plt.tight_layout()
plt.show()

df.hist(figsize=(12, 8), bins=30, edgecolor="black")
plt.suptitle("Sayısal Değişkenlerin Histogramı", fontsize=14)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sadece sayısal sütunları seç
numeric_df = df.select_dtypes(include=["int64", "float64"])

# Korelasyon matrisini hesapla
correlation_matrix = numeric_df.corr()

# Heatmap çizimi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix,
            annot=True,             # Hücrelerin içine korelasyon değerini yaz
            fmt=".2f",              # Virgülden sonra 2 basamak göster
            cmap="coolwarm",        # Renk skalası (soft mavi-kırmızı)
            linewidths=0.5,         # Hücreler arası çizgi
            linecolor='white',
            square=True,            # Kare kare hücreler
            cbar_kws={"shrink": .8})  # Sağdaki renk çubuğunu küçült

plt.title("📊 Sayısal Değişkenler Arası Korelasyon Matrisi", fontsize=14)
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 4))
for i, col in enumerate(['Rent', 'Size', 'Bathroom']):
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df[col], color='lightcoral')
    plt.title(f'{col} Boxplot')
plt.tight_layout()
plt.show()

def remove_outliers_iqr(df, column, factor=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - factor * IQR
    upper = Q3 + factor * IQR
    return df[(df[column] >= lower) & (df[column] <= upper)]

df_clean = df.copy()
for col in ['Rent', 'Size', 'Bathroom']:
    df_clean = remove_outliers_iqr(df_clean, col)

print("Temizlenmiş veri şekli:", df_clean.shape)

plt.figure(figsize=(15, 4))
for i, col in enumerate(['Rent', 'Size', 'Bathroom']):
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df_clean[col], color='mediumseagreen')
    plt.title(f'{col} (Temizlenmiş)')
plt.tight_layout()
plt.show()

# Gerekli kütüphanelerin import edilmesi

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import pandas as pd

# Google Drive'dan dosyayı okuma
df = pd.read_csv('/content/drive/MyDrive/House_Rent_Dataset.csv')
df = df[(df["Size"] >= 30) & (df["Size"] < 500)]



# İlk 5 satırı kontrol edelim
print(df.head())
print(df.columns)

# Kategorik değişkenleri one-hot encode et
df_encoded = pd.get_dummies(df, columns=['Furnishing Status', 'City', 'Area Type'], drop_first=True)

# Giriş değişkenleri (X) – daha kapsamlı
X = df_encoded[['Size', 'Bathroom', 'BHK'] +
               [col for col in df_encoded.columns if 'Furnishing Status_' in col or
                                                    'City_' in col or
                                                    'Area Type_' in col]]

# Hedef değişken (log dönüşümlü kira)
y = df_encoded['Rent']

from sklearn.model_selection import train_test_split

# Veriyi %80 eğitim, %20 test olacak şekilde ayır
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression

# Örnek veriyle model eğitimi (senin verilerinle eğitilmiş olduğunu varsayıyoruz)
model = LinearRegression()
model.fit(X_train, y_train)

# Katsayıları al
coefficients = model.coef_
intercept = model.intercept_

# Özellik isimlerini sırayla belirt (sadece bu üçünü istiyoruz)
feature_names = ['Size', 'Bathroom', 'BHK']

# Katsayıları sadece bu özellikler için yazdır
print("🔢 Regresyon Katsayıları:\n")
for name, coef in zip(feature_names, coefficients):
    print(f"{name}: {coef:.2f}")

# Sabit terimi yazdır
print(f"\n➕ Sabit Terim (Intercept): {intercept:.2f}")

"""📌 Regresyon Denklemi Nedir?
Rent = (37.89 × Size) + (11723.49 × Bathroom) + (3288.45 × BHK) + (-23142.29)
Bu, evin kira fiyatının logaritmasını (rent) tahmin eden doğrusal bir denklem.
Yani: Bir evin büyüklüğü, banyo sayısı ve oda sayısına göre kira değeri hesaplanıyor.
💡 Katsayıların Anlamı Nedir?
Özellik (Feature)	Katsayı	Ne Anlama Geliyor?
Size (m²)	37.89	Evin büyüklüğü 1 m² arttıkça, kira değeri 37.89 birim artar.
Bathroom	11723.49	1 banyo eklendiğinde, kira değeri 11723 birim artar. Banyo etkisi çok büyük!
BHK (Oda Sayısı)	3288.45	1 ekstra oda kira  değerini 3288 birim arttırır.
Intercept (Sabit)	-23142.29	Diğer tüm özellikler “0” olduğunda, modelin verdiği başlangıç tahmini budur. (Tek başına çok anlamlı değil, ama denklemin matematiksel dengesini sağlar.)

"""

from sklearn.preprocessing import StandardScaler

# Sayısal sütunları belirle
numeric_cols = ['Size', 'Bathroom', 'BHK']

# Ölçekleyici oluştur
scaler = StandardScaler()

# Sadece sayısal sütunları ölçeklendir
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Support Vector Regressor (SVR)": SVR()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"🔹 {name}")
    print(f"   Ortalama Kare Hata (MSE): {mse:.2f}")
    print(f"   R-Kare (R²): {r2:.3f}")
    print("-" * 40)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 🔹 Model sonuçları
results = {
    "Model": ["Linear Regression", "Decision Tree", "Random Forest", "SVR"],
    "MSE": [1905735826.05, 2292392322.41, 1450301215.78, 4310377563.72],
    "R2": [0.522, 0.425, 0.636, -0.082]
}

# 🔹 DataFrame'e dönüştür
results_df = pd.DataFrame(results)
results_df.set_index("Model", inplace=True)

# 🔹 Grafik - Soft tonlarda
plt.figure(figsize=(12, 5))

# 🔸 MSE grafiği (soft kırmızı ton)
plt.subplot(1, 2, 1)
sns.barplot(
    x=results_df.index,
    y=results_df["MSE"],
    palette=sns.color_palette("Reds", desat=0.6)  # Daha soft kırmızı
)
plt.title("🔴 Ortalama Kare Hata (MSE)")
plt.ylabel("Hata (düşük daha iyi)")
plt.xlabel("Model")
plt.xticks(rotation=45)

# 🔸 R2 grafiği (soft yeşil ton)
plt.subplot(1, 2, 2)
sns.barplot(
    x=results_df.index,
    y=results_df["R2"],
    palette=sns.color_palette("Greens", desat=0.6)  # Daha soft yeşil
)
plt.title("🟢 R-Kare Skoru (R²)")
plt.ylabel("Başarı (yüksek daha iyi)")
plt.xlabel("Model")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Modeli tanımla
xgb_model = XGBRegressor(random_state=42)

# 2. Modeli eğit
xgb_model.fit(X_train, y_train)

# 3. Tahmin yap
y_pred = xgb_model.predict(X_test)

# 4. Değerlendirme metriklerini hesapla
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("🎯 XGBoost Regressor Performansı")
print(f"Ortalama Kare Hata (MSE): {mse:.2f}")
print(f"R-Kare (R²): {r2:.3f}")

# Modelin Önemli Değişkenlerini Görüntüleme (Feature Importance)

importances = xgb_model.feature_importances_
features = X.columns

importance_df = pd.DataFrame({
    "Özellik": features,
    "Önemi": importances
}).sort_values(by="Önemi", ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x="Önemi", y="Özellik", data=importance_df)
plt.title("XGBoost - Özellik Önemleri (Feature Importance)")
plt.tight_layout()
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Model
rf = RandomForestRegressor(random_state=42)

# Aranacak hiperparametre kombinasyonları
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# GridSearchCV (5 katlı çapraz doğrulama)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)

# Eğit
grid_search.fit(X_train, y_train)

# En iyi parametreleri yazdır
print("🔍 En iyi parametreler:", grid_search.best_params_)

# En iyi modeli al
best_rf = grid_search.best_estimator_

# Tahmin ve değerlendirme
from sklearn.metrics import mean_squared_error, r2_score

y_pred = best_rf.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"🔧 Optimize Random Forest MSE: {mse:.2f}")
print(f"🔧 Optimize Random Forest R²: {r2:.2f}")

rf_opt = grid_search.best_estimator_


importances = rf_opt.feature_importances_
features = X.columns

# Görselleştir
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.barplot(x=importances, y=features)
plt.title("📊 Özelliklerin Önem Düzeyleri (Feature Importance)")
plt.xlabel("Önem Skoru")
plt.ylabel("Özellik")
plt.tight_layout()
plt.show()

y_pred = rf_opt.predict(X_test)

plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')  # Doğrusal referans
plt.xlabel("Gerçek Değer (Log_Rent)")
plt.ylabel("Tahmin Edilen Değer")
plt.title("🎯 Gerçek vs Tahmin Değerleri")
plt.tight_layout()
plt.show()

import shap

# Veriyi NumPy formatına çevir (çok önemli!)
X_train_array = X_train if isinstance(X_train, np.ndarray) else X_train.to_numpy()
X_test_array = X_test if isinstance(X_test, np.ndarray) else X_test.to_numpy()

# Explainer oluştur
explainer = shap.Explainer(xgb_model)

# SHAP değerlerini hesapla
shap_values = explainer(X_test_array)

# SHAP özet grafiği
shap.summary_plot(shap_values, X_test_array, feature_names=X.columns)

# rf_opt modeli RandomForest olmalı
importances = rf_opt.feature_importances_
features = X.columns

importance_df = pd.DataFrame({
    "Özellik": features,
    "Önemi": importances
}).sort_values(by="Önemi", ascending=False)

# Görselleştir
plt.figure(figsize=(10,6))
sns.barplot(x="Önemi", y="Özellik", data=importance_df, palette="viridis")
plt.title("📊 Kira Tahmini - Özellik Önemleri (Random Forest)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# 🧹 Eğer string gibi gelmişse sayıya çevir


# 1. Veriyi böl
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 2. Ölçekleme (bazı regresyon modelleri için önemli)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Modeli oluştur ve eğit
model = RandomForestRegressor(random_state=42)
model.fit(X_train_scaled, y_train)

# 4. Rastgele 5 ev seç
random_5 = X.sample(5, random_state=42)
random_5_scaled = scaler.transform(random_5)

# 5. Tahmin yap
predicted_rents = model.predict(random_5_scaled)

# 6. Sonuçları göster
results = random_5.copy()
results["Tahmin Edilen Kira"] = predicted_rents.round(2)

print("🏠 Rastgele 5 Ev İçin Kira Tahmini:\n")
print(results)

# 🔹 1. Hayali evin özelliklerini tanımla
new_house = pd.DataFrame([{
    "BHK": 2,
    "Size": 100,
    "Bathroom": 2,
    "Furnishing Status_Furnished": 0,
    "Furnishing Status_Semi-Furnished": 0,
    "Tenant Preferred_Bachelors": 0,
    "Tenant Preferred_Family": 1,
    "Tenant Preferred_Company": 0,
    # diğer one-hot encoded kolonlar varsa onları da 0 ile ekle
}])

# 🔹 2. Eksik sütunları tamamla
for col in X.columns:
    if col not in new_house.columns:
        new_house[col] = 0

# 🔹 3. Sıralamayı eşitle
new_house = new_house[X.columns]

# 🔹 4. Ölçekle
new_house_scaled = scaler.transform(new_house)

# 🔹 5. Tahmin yap
predicted_rent = model.predict(new_house_scaled)[0]

# 🔹 6. Sonucu yazdır
print("🏠 Hayali Ev Tahmini:")
print(f"Bu evin tahmini kirası: ₹{round(predicted_rent, 2)}")

# Y test seti ve X test seti üzerinden tahmin yap
y_pred = model.predict(X_test_scaled)  # Modeline göre ölçeklenmiş hali olabilir

# Tahminleri ve gerçekleri DataFrame olarak birleştir
comparison_df = pd.DataFrame({
    "Gerçek Kira (Log)": y_test,
    "Tahmin Edilen Kira (Log)": y_pred
})

# İsteğe bağlı: log dönüşümünü geri al (eğer y log dönüşümlüyse)
comparison_df["Gerçek Kira"] = np.exp(comparison_df["Gerçek Kira (Log)"])
comparison_df["Tahmin Edilen Kira"] = np.exp(comparison_df["Tahmin Edilen Kira (Log)"])

# İlk 10 örneği göster
comparison_df.head(10)

import joblib
joblib.dump(rf_opt, "random_forest_model.pkl")
joblib.dump(model,"regresyon_modeli.pkl")
joblib.dump(scaler,"veri_olcekleyici.pkl")

from google.colab import files
files.download("regresyon_modeli.pkl")
files.download("veri_olcekleyici.pkl")
files.download("random_forest_model.pkl")