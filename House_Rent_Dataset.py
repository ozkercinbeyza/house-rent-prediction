# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MaN5y-HQeLdzOLU5Oq1jOLe7fZJUDtcR
"""

# Google Drive'Ä± kullanabilmek iÃ§in 'drive' modÃ¼lÃ¼nÃ¼ Google Colab'dan iÃ§e aktarÄ±yoruz
from google.colab import drive

# Drive'Ä± baÄŸlamak iÃ§in bu komutu Ã§alÄ±ÅŸtÄ±rÄ±yoruz
drive.mount('/content/drive')

# Gerekli kÃ¼tÃ¼phaneleri iÃ§e aktarÄ±yoruz
import pandas as pd  # veri analizi iÃ§in en popÃ¼ler kÃ¼tÃ¼phane

# CSV dosyasÄ±nÄ± pandas ile okuyoruz
file_path = '/content/drive/MyDrive/House_Rent_Dataset.csv'  # dosya yolu
df = pd.read_csv(file_path)  # CSV dosyasÄ±nÄ± DataFrame olarak okuruz
print("Dosya baÅŸarÄ±yla yÃ¼klendi ve veri Ã§erÃ§evesine aktarÄ±ldÄ±")

# Veri Ã§erÃ§evesinin ilk 5 satÄ±rÄ±nÄ± gÃ¶rÃ¼ntÃ¼lemek iÃ§in:
df.head()

# Veri seti hakkÄ±nda genel bilgi almak iÃ§in:
df.info()  # Hangi sÃ¼tunlar var, veri tipleri neler, eksik veri var mÄ± gibi bilgiler verir

# SÃ¼tun adlarÄ±nÄ± listelemek iÃ§in
df.columns  # TÃ¼m sÃ¼tun isimlerini verir

#SayÄ±sal deÄŸiÅŸkenler iÃ§in istatistiksel Ã¶zet
df.describe()

# Veri kÃ¼mesinin boyutu (satÄ±r,sÃ¼tun sayÄ±sÄ±)
df.shape

#Her sÃ¼tunun veri tipini gÃ¶sterme
df.dtypes

#Her sÃ¼tundaki benzersiz deÄŸerleri gÃ¶sterme
df.nunique()

#Her sÃ¼tunda toplam eksik deÄŸer sayÄ±sÄ±
df.isnull().sum()

df.sample(5)

# Gerekli kÃ¼tÃ¼phaneler
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Åžehir ve mobilya daÄŸÄ±lÄ±mÄ± hesaplanÄ±yor
city_counts = df['City'].value_counts()
furnishing_counts = df['Furnishing Status'].value_counts()

# ðŸŽ¨ Soft mavi tonlar paleti
soft_blues = ["#ADD8E6", "#B0E0E6", "#AFEEEE", "#87CEEB", "#D0E7F5"]

# ðŸ“Š Åžehirlerin daÄŸÄ±lÄ±mÄ±
plt.figure(figsize=(10, 6))
sns.barplot(
    x=city_counts.index,
    y=city_counts.values,
    palette=soft_blues
)
plt.title("Åžehir BazÄ±nda Ev SayÄ±larÄ±", fontsize=16)
plt.xlabel("Åžehir", fontsize=12)
plt.ylabel("Ev SayÄ±sÄ±", fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# ðŸ“Š Mobilya durumlarÄ±
plt.figure(figsize=(8, 5))
sns.barplot(
    x=furnishing_counts.index,
    y=furnishing_counts.values,
    palette=soft_blues[:len(furnishing_counts)]  # Renk sayÄ±sÄ±nÄ± duruma gÃ¶re kÄ±salt
)
plt.title("Mobilya Durumuna GÃ¶re Ev SayÄ±sÄ±", fontsize=16)
plt.xlabel("Mobilya Durumu", fontsize=12)
plt.ylabel("Ev SayÄ±sÄ±", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 90 mÂ² ve Ã¼zeri evleri filtrele
df_filtered = df[df["Size"] >= 90]

# Ortalama kira deÄŸerlerini hesapla
size_rent = df_filtered.groupby("Size")["Rent"].mean().reset_index()

# Gerekirse ilk 30 deÄŸeri al
size_rent = size_rent.sort_values(by="Size").head(30)

# Grafik
plt.figure(figsize=(14, 6))
sns.barplot(data=size_rent, x="Size", y="Rent", color="#87CEEB")  # soft mavi (sky blue)

plt.title("ðŸ“ 90 mÂ² ve Ãœzeri Evler Ä°Ã§in Ortalama Kira", fontsize=14)
plt.xlabel("Ev BÃ¼yÃ¼klÃ¼ÄŸÃ¼ (mÂ²)")
plt.ylabel("Ortalama Kira (â‚¹)")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.5)
plt.tight_layout()
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Åžehirlere gÃ¶re ortalama kira hesapla
city_rent = df.groupby("City")["Rent"].mean().reset_index().sort_values(by="Rent", ascending=False)

# Grafik Ã§izimi
plt.figure(figsize=(10, 6))
sns.barplot(data=city_rent, x="City", y="Rent", color="#ADD8E6")  # LightBlue tonu

# BaÅŸlÄ±k ve eksen etiketleri
plt.title("ðŸ™ï¸ Åžehirlere GÃ¶re Ortalama Kira", fontsize=14)
plt.xlabel("Åžehir")
plt.ylabel("Ortalama Kira (â‚¹)")
plt.xticks(rotation=45)
plt.grid(axis="y", linestyle="--", alpha=0.4)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ðŸ”¹ BHK (oda sayÄ±sÄ±) gÃ¶re ortalama kira hesapla
bhk_rent = df.groupby("BHK")["Rent"].mean().reset_index()

# ðŸ”¹ Grafik
plt.figure(figsize=(8, 5))
sns.barplot(data=bhk_rent, x="BHK", y="Rent", palette="Blues")
plt.title("ðŸ›ï¸ Oda SayÄ±sÄ±na GÃ¶re Ortalama Kira (Rent)", fontsize=13)
plt.xlabel("Oda SayÄ±sÄ± (BHK)", fontsize=12)
plt.ylabel("Ortalama Kira (â‚¹)", fontsize=12)
plt.tight_layout()
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ðŸ”¹ Ã–rnek: Banyo ve kira bilgileri olan bir DataFrame'in olduÄŸunu varsayÄ±yoruz.
# df iÃ§inde "Bathroom" ve "Rent" sÃ¼tunlarÄ±nÄ±n bulunduÄŸundan emin olalÄ±m.

# ðŸ” Banyo sayÄ±sÄ±na gÃ¶re ortalama kira hesaplanÄ±yor
bathroom_rent = df.groupby("Bathroom")["Rent"].mean().reset_index()

# ðŸŽ¨ Grafik Ã§izimi
plt.figure(figsize=(8, 5))  # Grafik boyutu
sns.barplot(
    data=bathroom_rent,        # Veri kaynaÄŸÄ±
    x="Bathroom",              # X ekseni: Banyo sayÄ±sÄ±
    y="Rent",                  # Y ekseni: Ortalama kira
    palette="Blues"            # Soft mavi tonlar
)

# ðŸ–¼ï¸ BaÅŸlÄ±k ve eksen adlarÄ±
plt.title("ðŸ› Banyo SayÄ±sÄ±na GÃ¶re Ortalama Kira", fontsize=14)
plt.xlabel("Banyo SayÄ±sÄ±", fontsize=12)
plt.ylabel("Ortalama Kira (â‚¹)", fontsize=12)

# ðŸ§¼ ArayÃ¼z dÃ¼zenlemeleri
plt.tight_layout()
plt.show()

df.hist(figsize=(12, 8), bins=30, edgecolor="black")
plt.suptitle("SayÄ±sal DeÄŸiÅŸkenlerin HistogramÄ±", fontsize=14)
plt.show()

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Sadece sayÄ±sal sÃ¼tunlarÄ± seÃ§
numeric_df = df.select_dtypes(include=["int64", "float64"])

# Korelasyon matrisini hesapla
correlation_matrix = numeric_df.corr()

# Heatmap Ã§izimi
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix,
            annot=True,             # HÃ¼crelerin iÃ§ine korelasyon deÄŸerini yaz
            fmt=".2f",              # VirgÃ¼lden sonra 2 basamak gÃ¶ster
            cmap="coolwarm",        # Renk skalasÄ± (soft mavi-kÄ±rmÄ±zÄ±)
            linewidths=0.5,         # HÃ¼creler arasÄ± Ã§izgi
            linecolor='white',
            square=True,            # Kare kare hÃ¼creler
            cbar_kws={"shrink": .8})  # SaÄŸdaki renk Ã§ubuÄŸunu kÃ¼Ã§Ã¼lt

plt.title("ðŸ“Š SayÄ±sal DeÄŸiÅŸkenler ArasÄ± Korelasyon Matrisi", fontsize=14)
plt.tight_layout()
plt.show()

plt.figure(figsize=(15, 4))
for i, col in enumerate(['Rent', 'Size', 'Bathroom']):
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df[col], color='lightcoral')
    plt.title(f'{col} Boxplot')
plt.tight_layout()
plt.show()

def remove_outliers_iqr(df, column, factor=1.5):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower = Q1 - factor * IQR
    upper = Q3 + factor * IQR
    return df[(df[column] >= lower) & (df[column] <= upper)]

df_clean = df.copy()
for col in ['Rent', 'Size', 'Bathroom']:
    df_clean = remove_outliers_iqr(df_clean, col)

print("TemizlenmiÅŸ veri ÅŸekli:", df_clean.shape)

plt.figure(figsize=(15, 4))
for i, col in enumerate(['Rent', 'Size', 'Bathroom']):
    plt.subplot(1, 3, i+1)
    sns.boxplot(y=df_clean[col], color='mediumseagreen')
    plt.title(f'{col} (TemizlenmiÅŸ)')
plt.tight_layout()
plt.show()

# Gerekli kÃ¼tÃ¼phanelerin import edilmesi

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import pandas as pd

# Google Drive'dan dosyayÄ± okuma
df = pd.read_csv('/content/drive/MyDrive/House_Rent_Dataset.csv')
df = df[(df["Size"] >= 30) & (df["Size"] < 500)]



# Ä°lk 5 satÄ±rÄ± kontrol edelim
print(df.head())
print(df.columns)

# Kategorik deÄŸiÅŸkenleri one-hot encode et
df_encoded = pd.get_dummies(df, columns=['Furnishing Status', 'City', 'Area Type'], drop_first=True)

# GiriÅŸ deÄŸiÅŸkenleri (X) â€“ daha kapsamlÄ±
X = df_encoded[['Size', 'Bathroom', 'BHK'] +
               [col for col in df_encoded.columns if 'Furnishing Status_' in col or
                                                    'City_' in col or
                                                    'Area Type_' in col]]

# Hedef deÄŸiÅŸken (log dÃ¶nÃ¼ÅŸÃ¼mlÃ¼ kira)
y = df_encoded['Rent']

from sklearn.model_selection import train_test_split

# Veriyi %80 eÄŸitim, %20 test olacak ÅŸekilde ayÄ±r
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.linear_model import LinearRegression

# Ã–rnek veriyle model eÄŸitimi (senin verilerinle eÄŸitilmiÅŸ olduÄŸunu varsayÄ±yoruz)
model = LinearRegression()
model.fit(X_train, y_train)

# KatsayÄ±larÄ± al
coefficients = model.coef_
intercept = model.intercept_

# Ã–zellik isimlerini sÄ±rayla belirt (sadece bu Ã¼Ã§Ã¼nÃ¼ istiyoruz)
feature_names = ['Size', 'Bathroom', 'BHK']

# KatsayÄ±larÄ± sadece bu Ã¶zellikler iÃ§in yazdÄ±r
print("ðŸ”¢ Regresyon KatsayÄ±larÄ±:\n")
for name, coef in zip(feature_names, coefficients):
    print(f"{name}: {coef:.2f}")

# Sabit terimi yazdÄ±r
print(f"\nâž• Sabit Terim (Intercept): {intercept:.2f}")

"""ðŸ“Œ Regresyon Denklemi Nedir?
Rent = (37.89 Ã— Size) + (11723.49 Ã— Bathroom) + (3288.45 Ã— BHK) + (-23142.29)
Bu, evin kira fiyatÄ±nÄ±n logaritmasÄ±nÄ± (rent) tahmin eden doÄŸrusal bir denklem.
Yani: Bir evin bÃ¼yÃ¼klÃ¼ÄŸÃ¼, banyo sayÄ±sÄ± ve oda sayÄ±sÄ±na gÃ¶re kira deÄŸeri hesaplanÄ±yor.
ðŸ’¡ KatsayÄ±larÄ±n AnlamÄ± Nedir?
Ã–zellik (Feature)	KatsayÄ±	Ne Anlama Geliyor?
Size (mÂ²)	37.89	Evin bÃ¼yÃ¼klÃ¼ÄŸÃ¼ 1 mÂ² arttÄ±kÃ§a, kira deÄŸeri 37.89 birim artar.
Bathroom	11723.49	1 banyo eklendiÄŸinde, kira deÄŸeri 11723 birim artar. Banyo etkisi Ã§ok bÃ¼yÃ¼k!
BHK (Oda SayÄ±sÄ±)	3288.45	1 ekstra oda kira  deÄŸerini 3288 birim arttÄ±rÄ±r.
Intercept (Sabit)	-23142.29	DiÄŸer tÃ¼m Ã¶zellikler â€œ0â€ olduÄŸunda, modelin verdiÄŸi baÅŸlangÄ±Ã§ tahmini budur. (Tek baÅŸÄ±na Ã§ok anlamlÄ± deÄŸil, ama denklemin matematiksel dengesini saÄŸlar.)

"""

from sklearn.preprocessing import StandardScaler

# SayÄ±sal sÃ¼tunlarÄ± belirle
numeric_cols = ['Size', 'Bathroom', 'BHK']

# Ã–lÃ§ekleyici oluÅŸtur
scaler = StandardScaler()

# Sadece sayÄ±sal sÃ¼tunlarÄ± Ã¶lÃ§eklendir
X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])
X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score

models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Support Vector Regressor (SVR)": SVR()
}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"ðŸ”¹ {name}")
    print(f"   Ortalama Kare Hata (MSE): {mse:.2f}")
    print(f"   R-Kare (RÂ²): {r2:.3f}")
    print("-" * 40)

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# ðŸ”¹ Model sonuÃ§larÄ±
results = {
    "Model": ["Linear Regression", "Decision Tree", "Random Forest", "SVR"],
    "MSE": [1905735826.05, 2292392322.41, 1450301215.78, 4310377563.72],
    "R2": [0.522, 0.425, 0.636, -0.082]
}

# ðŸ”¹ DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
results_df = pd.DataFrame(results)
results_df.set_index("Model", inplace=True)

# ðŸ”¹ Grafik - Soft tonlarda
plt.figure(figsize=(12, 5))

# ðŸ”¸ MSE grafiÄŸi (soft kÄ±rmÄ±zÄ± ton)
plt.subplot(1, 2, 1)
sns.barplot(
    x=results_df.index,
    y=results_df["MSE"],
    palette=sns.color_palette("Reds", desat=0.6)  # Daha soft kÄ±rmÄ±zÄ±
)
plt.title("ðŸ”´ Ortalama Kare Hata (MSE)")
plt.ylabel("Hata (dÃ¼ÅŸÃ¼k daha iyi)")
plt.xlabel("Model")
plt.xticks(rotation=45)

# ðŸ”¸ R2 grafiÄŸi (soft yeÅŸil ton)
plt.subplot(1, 2, 2)
sns.barplot(
    x=results_df.index,
    y=results_df["R2"],
    palette=sns.color_palette("Greens", desat=0.6)  # Daha soft yeÅŸil
)
plt.title("ðŸŸ¢ R-Kare Skoru (RÂ²)")
plt.ylabel("BaÅŸarÄ± (yÃ¼ksek daha iyi)")
plt.xlabel("Model")
plt.xticks(rotation=45)

plt.tight_layout()
plt.show()

from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Modeli tanÄ±mla
xgb_model = XGBRegressor(random_state=42)

# 2. Modeli eÄŸit
xgb_model.fit(X_train, y_train)

# 3. Tahmin yap
y_pred = xgb_model.predict(X_test)

# 4. DeÄŸerlendirme metriklerini hesapla
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ðŸŽ¯ XGBoost Regressor PerformansÄ±")
print(f"Ortalama Kare Hata (MSE): {mse:.2f}")
print(f"R-Kare (RÂ²): {r2:.3f}")

# Modelin Ã–nemli DeÄŸiÅŸkenlerini GÃ¶rÃ¼ntÃ¼leme (Feature Importance)

importances = xgb_model.feature_importances_
features = X.columns

importance_df = pd.DataFrame({
    "Ã–zellik": features,
    "Ã–nemi": importances
}).sort_values(by="Ã–nemi", ascending=False)

plt.figure(figsize=(10,6))
sns.barplot(x="Ã–nemi", y="Ã–zellik", data=importance_df)
plt.title("XGBoost - Ã–zellik Ã–nemleri (Feature Importance)")
plt.tight_layout()
plt.show()

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestRegressor

# Model
rf = RandomForestRegressor(random_state=42)

# Aranacak hiperparametre kombinasyonlarÄ±
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5, 10]
}

# GridSearchCV (5 katlÄ± Ã§apraz doÄŸrulama)
grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,
                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)

# EÄŸit
grid_search.fit(X_train, y_train)

# En iyi parametreleri yazdÄ±r
print("ðŸ” En iyi parametreler:", grid_search.best_params_)

# En iyi modeli al
best_rf = grid_search.best_estimator_

# Tahmin ve deÄŸerlendirme
from sklearn.metrics import mean_squared_error, r2_score

y_pred = best_rf.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"ðŸ”§ Optimize Random Forest MSE: {mse:.2f}")
print(f"ðŸ”§ Optimize Random Forest RÂ²: {r2:.2f}")

rf_opt = grid_search.best_estimator_


importances = rf_opt.feature_importances_
features = X.columns

# GÃ¶rselleÅŸtir
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.barplot(x=importances, y=features)
plt.title("ðŸ“Š Ã–zelliklerin Ã–nem DÃ¼zeyleri (Feature Importance)")
plt.xlabel("Ã–nem Skoru")
plt.ylabel("Ã–zellik")
plt.tight_layout()
plt.show()

y_pred = rf_opt.predict(X_test)

plt.figure(figsize=(6, 6))
sns.scatterplot(x=y_test, y=y_pred)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')  # DoÄŸrusal referans
plt.xlabel("GerÃ§ek DeÄŸer (Log_Rent)")
plt.ylabel("Tahmin Edilen DeÄŸer")
plt.title("ðŸŽ¯ GerÃ§ek vs Tahmin DeÄŸerleri")
plt.tight_layout()
plt.show()

import shap

# Veriyi NumPy formatÄ±na Ã§evir (Ã§ok Ã¶nemli!)
X_train_array = X_train if isinstance(X_train, np.ndarray) else X_train.to_numpy()
X_test_array = X_test if isinstance(X_test, np.ndarray) else X_test.to_numpy()

# Explainer oluÅŸtur
explainer = shap.Explainer(xgb_model)

# SHAP deÄŸerlerini hesapla
shap_values = explainer(X_test_array)

# SHAP Ã¶zet grafiÄŸi
shap.summary_plot(shap_values, X_test_array, feature_names=X.columns)

# rf_opt modeli RandomForest olmalÄ±
importances = rf_opt.feature_importances_
features = X.columns

importance_df = pd.DataFrame({
    "Ã–zellik": features,
    "Ã–nemi": importances
}).sort_values(by="Ã–nemi", ascending=False)

# GÃ¶rselleÅŸtir
plt.figure(figsize=(10,6))
sns.barplot(x="Ã–nemi", y="Ã–zellik", data=importance_df, palette="viridis")
plt.title("ðŸ“Š Kira Tahmini - Ã–zellik Ã–nemleri (Random Forest)")
plt.tight_layout()
plt.show()

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
# ðŸ§¹ EÄŸer string gibi gelmiÅŸse sayÄ±ya Ã§evir


# 1. Veriyi bÃ¶l
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


# 2. Ã–lÃ§ekleme (bazÄ± regresyon modelleri iÃ§in Ã¶nemli)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 3. Modeli oluÅŸtur ve eÄŸit
model = RandomForestRegressor(random_state=42)
model.fit(X_train_scaled, y_train)

# 4. Rastgele 5 ev seÃ§
random_5 = X.sample(5, random_state=42)
random_5_scaled = scaler.transform(random_5)

# 5. Tahmin yap
predicted_rents = model.predict(random_5_scaled)

# 6. SonuÃ§larÄ± gÃ¶ster
results = random_5.copy()
results["Tahmin Edilen Kira"] = predicted_rents.round(2)

print("ðŸ  Rastgele 5 Ev Ä°Ã§in Kira Tahmini:\n")
print(results)

# ðŸ”¹ 1. Hayali evin Ã¶zelliklerini tanÄ±mla
new_house = pd.DataFrame([{
    "BHK": 2,
    "Size": 100,
    "Bathroom": 2,
    "Furnishing Status_Furnished": 0,
    "Furnishing Status_Semi-Furnished": 0,
    "Tenant Preferred_Bachelors": 0,
    "Tenant Preferred_Family": 1,
    "Tenant Preferred_Company": 0,
    # diÄŸer one-hot encoded kolonlar varsa onlarÄ± da 0 ile ekle
}])

# ðŸ”¹ 2. Eksik sÃ¼tunlarÄ± tamamla
for col in X.columns:
    if col not in new_house.columns:
        new_house[col] = 0

# ðŸ”¹ 3. SÄ±ralamayÄ± eÅŸitle
new_house = new_house[X.columns]

# ðŸ”¹ 4. Ã–lÃ§ekle
new_house_scaled = scaler.transform(new_house)

# ðŸ”¹ 5. Tahmin yap
predicted_rent = model.predict(new_house_scaled)[0]

# ðŸ”¹ 6. Sonucu yazdÄ±r
print("ðŸ  Hayali Ev Tahmini:")
print(f"Bu evin tahmini kirasÄ±: â‚¹{round(predicted_rent, 2)}")

# Y test seti ve X test seti Ã¼zerinden tahmin yap
y_pred = model.predict(X_test_scaled)  # Modeline gÃ¶re Ã¶lÃ§eklenmiÅŸ hali olabilir

# Tahminleri ve gerÃ§ekleri DataFrame olarak birleÅŸtir
comparison_df = pd.DataFrame({
    "GerÃ§ek Kira (Log)": y_test,
    "Tahmin Edilen Kira (Log)": y_pred
})

# Ä°steÄŸe baÄŸlÄ±: log dÃ¶nÃ¼ÅŸÃ¼mÃ¼nÃ¼ geri al (eÄŸer y log dÃ¶nÃ¼ÅŸÃ¼mlÃ¼yse)
comparison_df["GerÃ§ek Kira"] = np.exp(comparison_df["GerÃ§ek Kira (Log)"])
comparison_df["Tahmin Edilen Kira"] = np.exp(comparison_df["Tahmin Edilen Kira (Log)"])

# Ä°lk 10 Ã¶rneÄŸi gÃ¶ster
comparison_df.head(10)

import joblib
joblib.dump(rf_opt, "random_forest_model.pkl")
joblib.dump(model,"regresyon_modeli.pkl")
joblib.dump(scaler,"veri_olcekleyici.pkl")

from google.colab import files
files.download("regresyon_modeli.pkl")
files.download("veri_olcekleyici.pkl")
files.download("random_forest_model.pkl")